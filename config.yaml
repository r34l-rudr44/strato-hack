# Spacecraft Anomaly Detection Configuration
# StratoHack 2.0 - Problem Statement 2

# Data Settings
data:
  raw_dir: "data/raw"
  processed_dir: "data/processed"
  synthetic_dir: "data/synthetic"
  
  # OPSSAT-AD Dataset
  opssat:
    zenodo_url: "https://zenodo.org/records/12588359"
    n_samples: 2134
    
  # Synthetic data parameters (for demo)
  synthetic:
    n_channels: 10
    n_timesteps: 5000
    anomaly_ratio: 0.05
    noise_level: 0.1

# Preprocessing
preprocessing:
  window_size: 50
  stride: 10
  normalization: "standard"  # standard, minmax, robust
  
  # Feature engineering
  features:
    rolling_mean: true
    rolling_std: true
    rate_of_change: true
    fft_features: true

# Model Configuration
models:
  # Statistical Methods
  zscore:
    threshold: 3.0
    
  iqr:
    multiplier: 1.5
    
  # Isolation Forest
  isolation_forest:
    n_estimators: 100
    max_samples: "auto"
    contamination: 0.05
    random_state: 42
    
  # One-Class SVM
  one_class_svm:
    kernel: "rbf"
    gamma: "scale"
    nu: 0.05
    
  # LSTM Autoencoder
  autoencoder:
    hidden_dim: 64
    latent_dim: 16
    n_layers: 2
    dropout: 0.2
    learning_rate: 0.001
    epochs: 50
    batch_size: 32
    reconstruction_threshold: "auto"  # auto-computed from validation
    
  # Ensemble
  ensemble:
    voting: "soft"  # soft, hard
    weights: "learned"  # learned, equal

# Training
training:
  test_split: 0.2
  val_split: 0.1
  random_seed: 42
  
  # Cross-validation
  cv_folds: 5
  
  # Early stopping (for deep learning)
  early_stopping:
    patience: 10
    min_delta: 0.001

# Evaluation
evaluation:
  metrics:
    - accuracy
    - precision
    - recall
    - f1_score
    - roc_auc
    - pr_auc
    
  # Threshold optimization
  optimize_threshold: true
  threshold_metric: "f1_score"

# Visualization
visualization:
  figure_dir: "outputs/figures"
  dpi: 150
  style: "seaborn-v0_8-whitegrid"
  
  plots:
    - anomaly_timeline
    - roc_curve
    - precision_recall
    - confusion_matrix
    - feature_importance
    - score_distribution
    - model_comparison

# Output
output:
  models_dir: "outputs/models"
  reports_dir: "outputs/reports"
  
  # Save formats
  save_models: true
  save_predictions: true
  generate_report: true

# Logging
logging:
  level: "INFO"
  file: "outputs/training.log"
